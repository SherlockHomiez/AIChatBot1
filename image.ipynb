{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1377028223.py, line 57)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[4], line 57\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(text += line.response)\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "import easyocr\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Set the path for Tesseract-OCR if necessary\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "def extract_text_from_image(image_path):\n",
    "    # Open the image\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # Use pytesseract for printed text\n",
    "    print(\"Extracting printed text...\")\n",
    "    printed_text = pytesseract.image_to_string(image)\n",
    "    print(\"Printed text extracted:\")\n",
    "    print(printed_text)\n",
    "\n",
    "    # Use easyocr for handwritten text\n",
    "    reader = easyocr.Reader(['en'])\n",
    "    print(\"Extracting handwritten text...\")\n",
    "    results = reader.readtext(image_path)\n",
    "\n",
    "    handwritten_text = \"\"\n",
    "    for (bbox, text, prob) in results:\n",
    "        handwritten_text += text + \" \"\n",
    "    \n",
    "    print(\"Handwritten text extracted:\")\n",
    "    print(handwritten_text)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    image_path = 'image.png'  # Change to your image path\n",
    "    extract_text_from_image(image_path)\n",
    "\n",
    "prompt = '''\n",
    "You are a homework solver bot, you will get two sets of text which are analyzed from a image, one will be analyzed from the perspective of printed text, while the other from handwriting\n",
    "Match the simillarities between the two and try to get the most accurate question, and then solve that question.\n",
    "\n",
    "The print analyzed text is: {1}\n",
    "The handwriting analyzed text is: {2}\n",
    "\n",
    "'''\n",
    "\n",
    "data = {\n",
    "    \"model\": \"llama3.2\", \n",
    "    \"prompt\": prompt,\n",
    "    \"stream\": True\n",
    "}\n",
    "\n",
    "url = \"http://localhost:11434/api/generate\"  \n",
    "headers = {'Content-Type': 'application/json'}\n",
    "response = requests.post(url, data=json.dumps(data), headers=headers, stream=True)\n",
    "text = \"\"\n",
    "for line in response.iter_lines():\n",
    "    if line:\n",
    "        text += line.response\n",
    "        print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download weights v0.0.1 to path C:\\Users\\Manit\\AppData\\Roaming\\Python\\Python310\\site-packages\\pix2tex\\model\\checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "weights.pth: 100%|██████████| 97.4M/97.4M [00:52<00:00, 1.94Mb/s]\n",
      "image_resizer.pth: 100%|██████████| 18.5M/18.5M [00:09<00:00, 1.99Mb/s]\n",
      "C:\\Users\\Manit\\AppData\\Roaming\\Python\\Python310\\site-packages\\pix2tex\\cli.py:84: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model.load_state_dict(torch.load(self.args.checkpoint, map_location=self.args.device))\n",
      "C:\\Users\\Manit\\AppData\\Roaming\\Python\\Python310\\site-packages\\pix2tex\\cli.py:90: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.image_resizer.load_state_dict(torch.load(os.path.join(os.path.dirname(self.args.checkpoint), 'image_resizer.pth'), map_location=self.args.device))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage.png\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m LatexOCR()\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\contextlib.py:79\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[1;32m---> 79\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pix2tex\\cli.py:115\u001b[0m, in \u001b[0;36mLatexOCR.__call__\u001b[1;34m(self, img, resize)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_pic \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m--> 115\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mminmax_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_dimensions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin_dimensions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_resizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mno_resize) \u001b[38;5;129;01mand\u001b[39;00m resize:\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pix2tex\\cli.py:47\u001b[0m, in \u001b[0;36mminmax_size\u001b[1;34m(img, max_dimensions, min_dimensions)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m([r \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m ratios]):\n\u001b[0;32m     46\u001b[0m         size \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(img\u001b[38;5;241m.\u001b[39msize)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mmax\u001b[39m(ratios)\n\u001b[1;32m---> 47\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBILINEAR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m min_dimensions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m# hypothesis: there is a dim in img smaller than min_dimensions, and return a proper dim >= min_dimensions\u001b[39;00m\n\u001b[0;32m     50\u001b[0m     padded_size \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mmax\u001b[39m(img_dim, min_dim) \u001b[38;5;28;01mfor\u001b[39;00m img_dim, min_dim \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(img\u001b[38;5;241m.\u001b[39msize, min_dimensions)]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\PIL\\Image.py:2297\u001b[0m, in \u001b[0;36mImage.resize\u001b[1;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[0;32m   2294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m box \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2295\u001b[0m     box \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize\n\u001b[1;32m-> 2297\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m box \u001b[38;5;241m==\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize:\n\u001b[0;32m   2298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m   2300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "from pix2tex.cli import LatexOCR\n",
    "from PIL import Image\n",
    "\n",
    "img = Image.open('image.png')\n",
    "model = LatexOCR()\n",
    "\n",
    "print(model(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
